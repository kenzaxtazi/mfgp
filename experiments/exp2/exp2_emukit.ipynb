{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44092c0-87e9-41b3-9356-048a4ee8c42c",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90f5db7b-5395-4d5d-9624-298733a7eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/kenzatazi/Documents/CDT/Code')\n",
    "\n",
    "from load import beas_sutlej_gauges, era5, data_dir\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import GPy\n",
    "import scipy as sp\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mfdgp.utils.metrics import msll, r2_low_vs_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d3cf61-9e60-402e-b56d-104888050963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emukit\n",
    "from emukit.model_wrappers.gpy_model_wrappers import GPyMultiOutputWrapper\n",
    "from emukit.multi_fidelity.models import GPyLinearMultiFidelityModel\n",
    "from emukit.multi_fidelity.convert_lists_to_array import convert_x_list_to_array, convert_xy_lists_to_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "652328cb-9625-4ba5-b5df-3a49b3e8a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da9fafb-928a-4d5e-b9b5-7842473b30d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b4d8701-d7df-4800-a23b-06713ac0e3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range\n",
    "minyear = 2000\n",
    "maxyear = 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aac2cafb-0201-41d1-89cc-7f1ca323591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cross-validation scheme\n",
    "all_station_dict = pd.read_csv(data_dir + 'bs_gauges/gauge_info.csv', index_col='station')\n",
    "cv_locs = np.load('/Users/kenzatazi/Documents/CDT/Code//mfdgp/experiments/exp2/cv_locs.npy')\n",
    "cv_locs = cv_locs.reshape(-1, 2)\n",
    "\n",
    "station_list = []\n",
    "for loc in cv_locs:\n",
    "    station_row = all_station_dict[(all_station_dict['lat'] == loc[1]) | (all_station_dict['lon'] == loc[0])]\n",
    "    station_list.append(str(np.array(station_row.index[0])))\n",
    "\n",
    "station_arr = np.array(station_list)\n",
    "\n",
    "# Split into five chunks\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "cv_train_list = []\n",
    "cv_test_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(station_arr):\n",
    "    hf_train, hf_test = station_arr[train_index], station_arr[test_index]\n",
    "    cv_train_list.append(hf_train)\n",
    "    cv_test_list.append(hf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ce600e4-2080-4584-b55f-953b9c731c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/kenzatazi/Documents/CDT/Code/load/beas_sutlej_gauges.py:34: FutureWarning:In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indus\n",
      "/Users/kenzatazi/Documents/CDT/Code/data/ERA5/combi_data_indus_02-2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/kenzatazi/Documents/CDT/Code/load/beas_sutlej_gauges.py:34: FutureWarning:In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indus\n",
      "/Users/kenzatazi/Documents/CDT/Code/data/ERA5/combi_data_indus_02-2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/kenzatazi/Documents/CDT/Code/load/beas_sutlej_gauges.py:34: FutureWarning:In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indus\n",
      "/Users/kenzatazi/Documents/CDT/Code/data/ERA5/combi_data_indus_02-2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/kenzatazi/Documents/CDT/Code/load/beas_sutlej_gauges.py:34: FutureWarning:In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indus\n",
      "/Users/kenzatazi/Documents/CDT/Code/data/ERA5/combi_data_indus_02-2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/kenzatazi/Documents/CDT/Code/load/beas_sutlej_gauges.py:34: FutureWarning:In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indus\n",
      "/Users/kenzatazi/Documents/CDT/Code/data/ERA5/combi_data_indus_02-2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/kenzatazi/miniconda3/envs/mfdgp/lib/python3.8/site-packages/numpy/lib/npyio.py:521: VisibleDeprecationWarning:Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "cv_x_train_hf = []\n",
    "cv_y_train_hf = []\n",
    "cv_x_train_lf = []\n",
    "cv_y_train_lf = []\n",
    "cv_x_val = []\n",
    "cv_y_val = []\n",
    "\n",
    "for i in range(len(cv_train_list)):\n",
    "\n",
    "    hf_train_list = []\n",
    "    for station in cv_train_list[i]:\n",
    "        station_ds = beas_sutlej_gauges.gauge_download(\n",
    "            station, minyear=minyear, maxyear=maxyear)\n",
    "        hf_train_list.append(station_ds.to_dataframe().dropna().reset_index())\n",
    "    hf_train_df = pd.concat(hf_train_list)\n",
    "\n",
    "    val_list = []\n",
    "    for station in cv_test_list[i]:\n",
    "        station_ds = beas_sutlej_gauges.gauge_download(\n",
    "            station, minyear=minyear, maxyear=maxyear)\n",
    "        val_list.append(station_ds.to_dataframe().dropna().reset_index())\n",
    "    val_df = pd.concat(val_list)\n",
    "\n",
    "    # era5.collect_ERA5('indus', minyear=minyear, maxyear=maxyear)\n",
    "    era5_df = era5.gauges_download(\n",
    "        list(cv_test_list[i]) + list(cv_train_list[i]), minyear=minyear, maxyear=maxyear)\n",
    "\n",
    "    lf_train_df = era5_df\n",
    "    \n",
    "    # Prepare data\n",
    "    \n",
    "    # Transformations\n",
    "    lf_train_df['tp_tr'], lf_lambda = sp.stats.boxcox(\n",
    "        lf_train_df['tp'].values + 0.01)\n",
    "    hf_train_df['tp_tr'] = sp.stats.boxcox(\n",
    "        hf_train_df['tp'].values + 0.01, lmbda=lf_lambda)\n",
    "    val_df['tp_tr'] = sp.stats.boxcox(\n",
    "        val_df['tp'].values + 0.01, lmbda=lf_lambda)\n",
    "\n",
    "    # Splitting\n",
    "    x_train_lf = lf_train_df[['time', 'lat', 'lon', 'z']].values.reshape(-1, 4)\n",
    "    y_train_lf = lf_train_df['tp_tr'].values.reshape(-1, 1)\n",
    "    x_train_hf = hf_train_df[['time', 'lat', 'lon', 'z']].values.reshape(-1, 4)\n",
    "    y_train_hf = hf_train_df[['tp_tr']].values.reshape(-1, 1)\n",
    "    x_val = val_df[['time', 'lat', 'lon', 'z']].values.reshape(-1, 4)\n",
    "    y_val = val_df['tp_tr'].values.reshape(-1, 1)\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler().fit(x_train_hf)\n",
    "    x_train_hf1 = scaler.transform(x_train_hf)\n",
    "    x_train_lf1 = scaler.transform(x_train_lf)\n",
    "    x_val1 = scaler.transform(x_val)\n",
    "    \n",
    "    cv_x_train_hf.append(x_train_hf1)\n",
    "    cv_y_train_hf.append(y_train_hf)\n",
    "    cv_x_train_lf.append(x_train_lf1)\n",
    "    cv_y_train_lf.append(y_train_lf)\n",
    "    cv_x_val.append(x_val1)\n",
    "    cv_y_val.append(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5718b0b2-a250-42c3-9df5-f7cb06d1db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/cv_x_train_hf_bs_2000-2005.npy', cv_x_train_hf)\n",
    "np.save('data/cv_y_train_hf_bs_2000-2005.npy', cv_y_train_hf)\n",
    "np.save('data/cv_x_train_lf_bs_2000-2005.npy', cv_x_train_lf)\n",
    "np.save('data/cv_y_train_lf_bs_2000-2005.npy', cv_y_train_lf)\n",
    "np.save('data/cv_y_val_bs_2000-2005.npy', cv_y_val)\n",
    "np.save('data/cv_x_val_bs_2000-2005.npy', cv_x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a286bb4f-a806-48d7-a341-dc0d96276316",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d40fe9c3-ede0-4e69-b183-08c030af91d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_x_train_hf = np.load('data/cv_x_train_hf_bs_2000-2005.npy', allow_pickle=True)\n",
    "cv_y_train_hf = np.load('data/cv_y_train_hf_bs_2000-2005.npy', allow_pickle=True)\n",
    "cv_x_train_lf = np.load('data/cv_x_train_lf_bs_2000-2005.npy', allow_pickle=True)\n",
    "cv_y_train_lf = np.load('data/cv_y_train_lf_bs_2000-2005.npy', allow_pickle=True)\n",
    "cv_x_val = np.load('data/cv_x_val_bs_2000-2005.npy', allow_pickle=True)\n",
    "cv_y_val = np.load('data/cv_y_val_bs_2000-2005.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf79536-415a-4b95-a761-ba327221399f",
   "metadata": {},
   "source": [
    "## MFDGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f731cf-6bd5-445d-a2d0-e4b519a02b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/kenzatazi/miniconda3/envs/mfdgp/lib/python3.8/site-packages/paramz/transformations.py:111: RuntimeWarning:divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart 1/5, f = 5194.871087215521\n",
      "Optimization restart 2/5, f = 4856.742384879695\n",
      "Optimization restart 3/5, f = 4787.651753490027\n",
      "Optimization restart 4/5, f = 4839.651074743749\n"
     ]
    }
   ],
   "source": [
    "R2_all = []\n",
    "RMSE_all = []\n",
    "RMSE_p5 = []\n",
    "RMSE_p95 = []\n",
    "MSLL = []\n",
    "\n",
    "R2_all_low = []\n",
    "RMSE_all_low = []\n",
    "RMSE_p5_low = []\n",
    "RMSE_p95_low = []\n",
    "MSLL_low = []\n",
    "\n",
    "r2_high_list = []\n",
    "r2_low_list = []\n",
    "\n",
    "for i in range(len(cv_train_list)):\n",
    "\n",
    "    # Input data\n",
    "    X_train, Y_train = convert_xy_lists_to_arrays([cv_x_train_lf[i], cv_x_train_hf[i]], [cv_y_train_lf[i], cv_y_train_hf[i]])\n",
    "\n",
    "    # Train and evaluate\n",
    "    kern1 = GPy.kern.RBF(input_dim=4, ARD=True)\n",
    "    kernels = [kern1, GPy.kern.RBF(input_dim=4, ARD=True)]\n",
    "    lin_mf_kernel = emukit.multi_fidelity.kernels.LinearMultiFidelityKernel(kernels)\n",
    "    gpy_lin_mf_model = GPyLinearMultiFidelityModel(X_train, Y_train, lin_mf_kernel, n_fidelities=2,)\n",
    "    gpy_lin_mf_model.mixed_noise.Gaussian_noise.fix(0)\n",
    "    gpy_lin_mf_model.mixed_noise.Gaussian_noise_1.fix(0)\n",
    "    lin_mf_model = GPyMultiOutputWrapper(gpy_lin_mf_model, 2, n_optimization_restarts=5)\n",
    "    lin_mf_model.optimize()\n",
    "    \n",
    "    with open('model_instances/bs_mfdgp' + str(i) + '.pkl', 'wb') as file:\n",
    "        pickle.dump(lin_mf_model, file)\n",
    "    \n",
    "    # Load and prep test data                                     \n",
    "    x_val1, y_val = cv_x_val[i], cv_y_val[i]                                                                                   \n",
    "    n = x_val1.shape[0]\n",
    "    x_met = convert_x_list_to_array([x_val1, x_val1])\n",
    "    \n",
    "    # ALL\n",
    "    y_pred0, y_var0 = lin_mf_model.predict(x_met[n:])\n",
    "    y_pred_low0, y_var_low0 = lin_mf_model.predict(x_met[:n])\n",
    "    \n",
    "    y_pred = sp.special.inv_boxcox(y_pred0, lf_lambda).reshape(-1)\n",
    "    y_true = sp.special.inv_boxcox(y_val, lf_lambda).reshape(-1)\n",
    "    R2_all.append(r2_score(y_true, y_pred))\n",
    "    RMSE_all.append(mean_squared_error(y_true, y_pred, squared=False))\n",
    "    \n",
    "    y_pred_low = sp.special.inv_boxcox(y_pred_low0, lf_lambda).reshape(-1)\n",
    "    R2_all_low.append(r2_score(y_true, y_pred_low))\n",
    "    RMSE_all_low.append(mean_squared_error(y_true, y_pred_low, squared=False))\n",
    "\n",
    "    # 5th PERCENTILE\n",
    "    p5 = np.percentile(y_true, 5.0)\n",
    "    indx = [y_true <= p5][0]\n",
    "    x_val_p5 = x_val[indx, :]\n",
    "    y_true_p5 = y_true[indx]\n",
    "    y_pred_p5 = y_pred[indx]\n",
    "    y_pred_p5_low = y_pred_low[indx]\n",
    "    RMSE_p5.append(mean_squared_error(y_true_p5, y_pred_p5, squared=False))\n",
    "    RMSE_p5_low.append(mean_squared_error(y_true_p5, y_pred_p5_low, squared=False))\n",
    "\n",
    "    # 95th PERCENTILE\n",
    "    p95 = np.percentile(y_true, 95.0)\n",
    "    indx = [y_true >= p95][0]\n",
    "    x_val_p95 = x_val[indx]\n",
    "    y_true_p95 = y_true[indx]\n",
    "    y_pred_p95 = y_pred[indx]\n",
    "    y_pred_p95_low = y_pred_low[indx]\n",
    "    RMSE_p95.append(mean_squared_error(y_true_p95, y_pred_p95, squared=False))\n",
    "    RMSE_p95_low.append(mean_squared_error(y_true_p95, y_pred_p95_low, squared=False))\n",
    "                        \n",
    "    # MSLL\n",
    "    ll = msll(y_val, y_pred0, y_var0)\n",
    "    ll_low = msll(y_val, y_pred_low0, y_var_low0)\n",
    "    MSLL.append(ll)\n",
    "    MSLL_low.append(ll_low)\n",
    "    \n",
    "    r2_high, r2_low = r2_low_vs_high(y_pred_low0, y_pred0, x_val1, y_val, lf_lambda)\n",
    "    r2_high_list.append(r2_high)\n",
    "    r2_low_list.append(r2_low)\n",
    "\n",
    "print('Mean RMSE = ', np.mean(RMSE_all), '±', np.std(RMSE_all))\n",
    "print('Mean R2 = ', np.mean(R2_all), '±', np.std(R2_all))\n",
    "print('5th RMSE = ', np.mean(RMSE_p5), '±', np.std(RMSE_p5))\n",
    "print('95th RMSE = ', np.mean(RMSE_p95), '±', np.std(RMSE_p95))\n",
    "print('MSLL= ', np.mean(MSLL), '±', np.std(MSLL))\n",
    "                        \n",
    "print('Mean RMSE = ', np.mean(RMSE_all_low), '±', np.std(RMSE_all_low))\n",
    "print('Mean R2 = ', np.mean(R2_all_low), '±', np.std(R2_all_low))\n",
    "print('5th RMSE = ', np.mean(RMSE_p5_low), '±', np.std(RMSE_p5_low))\n",
    "print('95th RMSE = ', np.mean(RMSE_p95_low), '±', np.std(RMSE_p95_low))\n",
    "print('MSLL= ', np.mean(MSLL_low), '±', np.std(MSLL_low))\n",
    "\n",
    "np.savetxt('exp2_ypred_lf_r2_2000-2005.csv', r2_low_list)\n",
    "np.savetxt('exp2_ypred_hf_r2_2000-2005.csv', r2_high_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6730b470-31a1-4963-bf72-13ac3deaa134",
   "metadata": {},
   "source": [
    "## GP model on HF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a41bc-8a1d-4b8c-9421-cd6468ea2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_all = []\n",
    "RMSE_all = []\n",
    "RMSE_p5 = []\n",
    "RMSE_p95 = []\n",
    "MSLL = []\n",
    "\n",
    "for i in range(len(cv_train_list)):\n",
    "\n",
    "    x_train_hf1, y_train_hf = cv_x_train_hf[i], cv_y_train_hf[i]\n",
    "    x_val1, y_val = cv_x_val[i], cv_y_val[i]\n",
    "    \n",
    "    # Input data\n",
    "    kernel = GPy.kern.StdPeriodic(1, active_dims=[0], period=1) * GPy.kern.RBF(1, active_dims=[0]) + GPy.kern.RBF(3, active_dims=[1,2,3], ARD=True)\n",
    "    m = GPy.models.GPRegression(x_train_hf1, y_train_hf, kernel)\n",
    "    m.optimize_restarts(num_restarts = 5)\n",
    "    \n",
    "    y_pred0, y_var0 = m.predict(x_val1)\n",
    "    \n",
    "    y_pred = sp.special.inv_boxcox(y_pred0, lf_lambda).reshape(-1)\n",
    "    y_true = sp.special.inv_boxcox(y_val, lf_lambda).reshape(-1)\n",
    "    R2_all.append(r2_score(y_true, y_pred))\n",
    "    RMSE_all.append(mean_squared_error(y_true, y_pred, squared=False))\n",
    "    \n",
    "    # 5th PERCENTILE\n",
    "    p5 = np.percentile(y_true, 5.0)\n",
    "    indx = [y_true <= p5][0]\n",
    "    x_val_p5 = x_val1[indx, :]\n",
    "    y_true_p5 = y_true[indx]\n",
    "    y_pred_p5 = y_pred[indx]\n",
    "    RMSE_p5.append(mean_squared_error(y_true_p5, y_pred_p5, squared=False))\n",
    "\n",
    "    # 95th PERCENTILE\n",
    "    p95 = np.percentile(y_true, 95.0)\n",
    "    indx = [y_true >= p95][0]\n",
    "    x_val_p95 = x_va1l[indx]\n",
    "    y_true_p95 = y_true[indx]\n",
    "    y_pred_p95 = y_pred[indx]\n",
    "    RMSE_p95.append(mean_squared_error(y_true_p95, y_pred_p95, squared=False))\n",
    "    \n",
    "    # MSLL\n",
    "    ll = msll(y_val, y_pred0, y_var0)\n",
    "    MSLL.append(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37d375f-47f3-4c2e-96ab-e01741a74af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GP on gauges')\n",
    "print('Mean RMSE = ', np.mean(RMSE_all), '±', np.std(RMSE_all))\n",
    "print('Mean R2 = ', np.mean(R2_all), '±', np.std(R2_all))\n",
    "print('5th RMSE = ', np.mean(RMSE_p5), '±', np.std(RMSE_p5))\n",
    "print('95th RMSE = ', np.mean(RMSE_p95), '±', np.std(RMSE_p95))\n",
    "print('MSLL= ', np.mean(MSLL), '±', np.std(MSLL))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285547f4-0580-4b98-8d54-25587275ee4f",
   "metadata": {},
   "source": [
    "## Linear regression on ERA5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2906480b-b385-4b21-b600-80627a23edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_all = []\n",
    "RMSE_all = []\n",
    "RMSE_p5 = []\n",
    "RMSE_p95 = []\n",
    "MSLL = []\n",
    "\n",
    "for i in range(len(cv_train_list)):\n",
    "\n",
    "    x_train_lf1, y_train_lf = cv_x_train_lf[i], cv_y_train_lf[i]\n",
    "    x_val1, y_val = cv_x_val[i], cv_y_val[i]\n",
    "    \n",
    "    # Train and evaluate\n",
    "    linear_m = LinearRegression()\n",
    "    linear_m.fit(x_train_lf1, y_train_lf)\n",
    "    y_pred0 = linear_m.predict(x_val1)\n",
    "   \n",
    "    # ALL\n",
    "    y_pred = sp.special.inv_boxcox(y_pred0, lf_lambda).reshape(-1)\n",
    "    y_true = sp.special.inv_boxcox(y_val, lf_lambda).reshape(-1)\n",
    "    R2_all.append(r2_score(y_true, y_pred))\n",
    "    RMSE_all.append(mean_squared_error(y_true, y_pred, squared=False))\n",
    "    \n",
    "    # 5th PERCENTILE\n",
    "    p5 = np.percentile(y_true, 5.0)\n",
    "    indx = [y_true <= p5][0]\n",
    "    x_val_p5 = x_val1[indx, :]\n",
    "    y_true_p5 = y_true[indx]\n",
    "    y_pred_p5 = y_pred[indx]\n",
    "    RMSE_p5.append(mean_squared_error(y_true_p5, y_pred_p5, squared=False))\n",
    "   \n",
    "    # 95th PERCENTILE\n",
    "    p95 = np.percentile(y_true, 95.0)\n",
    "    indx = [y_true >= p95][0]\n",
    "    x_val_p95 = x_val1[indx]\n",
    "    y_true_p95 = y_true[indx]\n",
    "    y_pred_p95 = y_pred[indx]\n",
    "    RMSE_p95.append(mean_squared_error(y_true_p95, y_pred_p95, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b041d64b-2c7e-4761-9df6-0f1404fde93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lin Reg on ERA5\n",
      "Mean RMSE =  4.2135738187990865 ± 0.9923927211777457\n",
      "Mean R2 =  -0.08486123275749909 ± 0.04647291696154646\n",
      "5th RMSE =  2.2099195905772446 ± 0.45099541469767646\n",
      "95th RMSE =  14.332707765350268 ± 4.027521028274967\n"
     ]
    }
   ],
   "source": [
    "print('Lin Reg on ERA5')\n",
    "print('Mean RMSE = ', np.mean(RMSE_all), '±', np.std(RMSE_all))\n",
    "print('Mean R2 = ', np.mean(R2_all), '±', np.std(R2_all))\n",
    "print('5th RMSE = ', np.mean(RMSE_p5), '±', np.std(RMSE_p5))\n",
    "print('95th RMSE = ', np.mean(RMSE_p95), '±', np.std(RMSE_p95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf78d4e-6c26-49fc-9684-fd6ff27b8e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
