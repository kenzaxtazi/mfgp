{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "220e1f89-e5db-4ea0-8762-c45193d0f19d",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90f5db7b-5395-4d5d-9624-298733a7eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/kenzatazi/Documents/CDT/Code')\n",
    "\n",
    "from load import era5, data_dir, value\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import GPy\n",
    "from tqdm import tqdm\n",
    "import scipy as sp\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from mfdgp.utils.metrics import msll, r2_low_vs_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070628eb-456f-4eb2-88e8-326efaa47f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d3cf61-9e60-402e-b56d-104888050963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emukit\n",
    "from emukit.model_wrappers.gpy_model_wrappers import GPyMultiOutputWrapper\n",
    "from emukit.multi_fidelity.models import GPyLinearMultiFidelityModel\n",
    "from emukit.multi_fidelity.convert_lists_to_array import convert_x_list_to_array, convert_xy_lists_to_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82901517-73c8-4c78-8383-f0a82b56bd31",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67eee07c-9b61-491e-a122-342ec97f4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "minyear = 1980\n",
    "maxyear = 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8763cd5-a051-4c68-a40e-cb625db31004",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge_df = value.all_gauge_data(minyear, maxyear, monthly=True)\n",
    "station_names = gauge_df.drop_duplicates('name')['name']\n",
    "\n",
    "# Get CV scheme\n",
    "cv_locs = np.load('/Users/kenzatazi/Documents/CDT/Code/mfdgp/experiments/exp1/cv/exp1_cv_locs.npy')\n",
    "cv_locs = cv_locs.reshape(-1, 2)\n",
    "\n",
    "station_list = []\n",
    "for loc in cv_locs:\n",
    "    station_row = gauge_df[(gauge_df['latitude'] == loc[1]) | (gauge_df['longitude'] == loc[0])].iloc[0]\n",
    "    station_list.append(station_row['name'])\n",
    "station_arr = np.array(station_list)\n",
    "\n",
    "# Split indexes\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "cv_train_list = []\n",
    "cv_test_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(station_arr):\n",
    "    hf_train, hf_test = station_arr[train_index], station_arr[test_index]\n",
    "    cv_train_list.append(hf_train)\n",
    "    cv_test_list.append(hf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31dd72f5-95ee-4295-ad43-9078fb4e57c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value\n",
      "/Users/kenzatazi/Documents/CDT/Code/data/ERA5/combi_data_value_03-2023.csv\n",
      "value\n",
      "/Users/kenzatazi/Documents/CDT/Code/data/ERA5/combi_data_value_03-2023.csv\n",
      "value\n",
      "/Users/kenzatazi/Documents/CDT/Code/data/ERA5/combi_data_value_03-2023.csv\n",
      "value\n",
      "/Users/kenzatazi/Documents/CDT/Code/data/ERA5/combi_data_value_03-2023.csv\n",
      "value\n",
      "/Users/kenzatazi/Documents/CDT/Code/data/ERA5/combi_data_value_03-2023.csv\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "cv_x_train_hf = []\n",
    "cv_y_train_hf = []\n",
    "cv_x_train_lf = []\n",
    "cv_y_train_lf = []\n",
    "cv_x_val = []\n",
    "cv_y_val = []\n",
    "lf_lambdas = []\n",
    "\n",
    "\n",
    "for i in range(len(cv_train_list)):\n",
    "\n",
    "    hf_train_list = []\n",
    "    for station in cv_train_list[i]:\n",
    "        station_ds = value.gauge_download(\n",
    "            station, minyear=minyear, maxyear=maxyear)\n",
    "        hf_train_list.append(station_ds.dropna().reset_index())\n",
    "    hf_train_df = pd.concat(hf_train_list)\n",
    "\n",
    "    val_list = []\n",
    "    for station in cv_test_list[i]:\n",
    "        station_ds = value.gauge_download(\n",
    "            station, minyear=minyear, maxyear=maxyear)\n",
    "        val_list.append(station_ds.dropna().reset_index())\n",
    "    val_df = pd.concat(val_list)\n",
    "\n",
    "    era5_df = era5.value_gauge_download(\n",
    "        list(cv_test_list[i]) + list(cv_train_list[i]), minyear=minyear, maxyear=maxyear)\n",
    "    \n",
    "    hf_train_df.sort_values(by='time', inplace=True)\n",
    "    val_df.sort_values(by='time', inplace=True)\n",
    "    lf_train_df = era5_df.reset_index().sort_values(by='time')\n",
    "    \n",
    "    # Prepare data\n",
    "    \n",
    "    # Transformations\n",
    "    lf_train_df['tp_tr'], lf_lambda = sp.stats.boxcox(\n",
    "        lf_train_df['tp'].values + 0.01)\n",
    "    hf_train_df['tp_tr'] = sp.stats.boxcox(\n",
    "        hf_train_df['tp'].values + 0.01, lmbda=lf_lambda)\n",
    "    val_df['tp_tr'] = sp.stats.boxcox(\n",
    "        val_df['tp'].values + 0.01, lmbda=lf_lambda)\n",
    "\n",
    "    # Splitting\n",
    "    x_train_lf = lf_train_df[['time', 'lat', 'lon', 'z']].values.reshape(-1, 4)\n",
    "    y_train_lf = lf_train_df['tp_tr'].values.reshape(-1, 1)\n",
    "    x_train_hf = hf_train_df[['time', 'latitude', 'longitude', 'altitude']].values.reshape(-1, 4)\n",
    "    y_train_hf = hf_train_df[['tp_tr']].values.reshape(-1, 1)\n",
    "    x_val = val_df[['time', 'latitude', 'longitude', 'altitude']].values.reshape(-1, 4)\n",
    "    y_val = val_df['tp_tr'].values.reshape(-1, 1)\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler().fit(x_train_hf)\n",
    "    x_train_hf1 = scaler.transform(x_train_hf)\n",
    "    x_train_lf1 = scaler.transform(x_train_lf)\n",
    "    x_val1 = scaler.transform(x_val)\n",
    "    \n",
    "    cv_x_train_hf.append(x_train_hf1)\n",
    "    cv_y_train_hf.append(y_train_hf)\n",
    "    cv_x_train_lf.append(x_train_lf1)\n",
    "    cv_y_train_lf.append(y_train_lf)\n",
    "    cv_x_val.append(x_val1)\n",
    "    cv_y_val.append(y_val)\n",
    "    lf_lambdas.append(lf_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09610bd6-825a-413a-8c50-2049ad2cb272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/kenzatazi/miniconda3/envs/mfdgp/lib/python3.8/site-packages/numpy/lib/npyio.py:521: VisibleDeprecationWarning:Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "np.save('data/cv_x_train_hf_value_1980-2010.npy', cv_x_train_hf)\n",
    "np.save('data/cv_y_train_hf_value_1980-2010.npy', cv_y_train_hf)\n",
    "np.save('data/cv_x_train_lf_value_1980-2010.npy', cv_x_train_lf)\n",
    "np.save('data/cv_y_train_lf_value_1980-2010.npy', cv_y_train_lf)\n",
    "np.save('data/cv_y_val_value_1980-2010.npy', cv_y_val)\n",
    "np.save('data/cv_x_val_value_1980-2010.npy', cv_x_val)\n",
    "np.save('data/lf_lambda_1980-2010.npy', lf_lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e92dcaa-731d-49f1-87a7-56806656a6d0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30e4949c-5fc3-44c8-bb6c-596ac9e61bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_x_train_hf = np.load('data/cv_x_train_hf_value_1980-2010.npy', allow_pickle=True)\n",
    "cv_y_train_hf = np.load('data/cv_y_train_hf_value_1980-2010.npy', allow_pickle=True)\n",
    "cv_x_train_lf = np.load('data/cv_x_train_lf_value_1980-2010.npy', allow_pickle=True)\n",
    "cv_y_train_lf = np.load('data/cv_y_train_lf_value_1980-2010.npy', allow_pickle=True)\n",
    "cv_x_val = np.load('data/cv_x_val_value_1980-2010.npy', allow_pickle=True)\n",
    "cv_y_val = np.load('data/cv_y_val_value_1980-2010.npy', allow_pickle=True)\n",
    "lf_lambdas = np.load('data/lf_lambda_1980-2010.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df60f008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_x_train_lf[i][:tr*28]\n",
    "tr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5c511-90bd-4d8a-be1d-ed0b939252c4",
   "metadata": {},
   "source": [
    "## MFDGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "370e155e-5a8c-4cfb-bb14-a4e1ce2b391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s] /Users/kenzatazi/miniconda3/envs/mfdgp/lib/python3.8/site-packages/paramz/transformations.py:111: RuntimeWarning:divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization restart 1/5, f = 668.4692951103332\n",
      "Optimization restart 2/5, f = 668.4692966885423\n",
      "Optimization restart 3/5, f = 668.4692957717396\n",
      "Optimization restart 4/5, f = 678.4084892326171\n",
      "Optimization restart 5/5, f = 678.4084884069007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/kenzatazi/miniconda3/envs/mfdgp/lib/python3.8/site-packages/paramz/transformations.py:111: RuntimeWarning:divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "R2_all = []\n",
    "\n",
    "for t in tqdm([1, 2, 4, 8, 15, 30]):\n",
    "\n",
    "    R2 = []\n",
    "\n",
    "    for i in range(len(cv_train_list)):\n",
    "\n",
    "        tr = 12 * t\n",
    "\n",
    "        # Input data\n",
    "        X_train, Y_train = convert_xy_lists_to_arrays([cv_x_train_lf[i][:tr*28], cv_x_train_hf[i][:tr*28]], [\n",
    "                                                      cv_y_train_lf[i][:tr*28], cv_y_train_hf[i][:tr*28]])\n",
    "\n",
    "        # Train and evaluate\n",
    "        kern1 = GPy.kern.Matern52(input_dim=4, ARD=True)\n",
    "        kernels = [kern1, GPy.kern.Matern52(input_dim=4, ARD=True)]\n",
    "        lin_mf_kernel = emukit.multi_fidelity.kernels.LinearMultiFidelityKernel(\n",
    "            kernels)\n",
    "        gpy_lin_mf_model = GPyLinearMultiFidelityModel(\n",
    "            X_train, Y_train, lin_mf_kernel, n_fidelities=2,)\n",
    "        gpy_lin_mf_model.mixed_noise.Gaussian_noise.fix(0)\n",
    "        gpy_lin_mf_model.mixed_noise.Gaussian_noise_1.fix(0)\n",
    "        lin_mf_model = GPyMultiOutputWrapper(\n",
    "            gpy_lin_mf_model, 2, n_optimization_restarts=5)\n",
    "        lin_mf_model.optimize()\n",
    "\n",
    "        # Load and prep test data\n",
    "        x_val1, y_val = cv_x_val[i][:tr*5], cv_y_val[i][:tr*5]\n",
    "        n = x_val1.shape[0]\n",
    "        x_met = convert_x_list_to_array([x_val1, x_val1])\n",
    "\n",
    "        # ALL\n",
    "        y_pred0, y_var0 = lin_mf_model.predict(x_met[n:])\n",
    "        y_pred_low0, y_var_low0 = lin_mf_model.predict(x_met[:n])\n",
    "\n",
    "        y_pred = sp.special.inv_boxcox(y_pred0, lf_lambdas[i]).reshape(-1)\n",
    "        y_true = sp.special.inv_boxcox(y_val, lf_lambdas[i]).reshape(-1)\n",
    "        R2.append(r2_score(y_true, y_pred))\n",
    "\n",
    "    print('Mean R2 = ', np.mean(R2), '±', np.std(R2))\n",
    "    R2_all.append([np.mean(R2), np.std(R2)])\n",
    "\n",
    "np.savetxt('app_c_value.npy', R2_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c03c873e-89ee-4963-9018-6a94d9c39292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE =  1.8554768746561332 ± 0.0\n",
      "Mean R2 =  0.4456420375310417 ± 0.0\n",
      "5th RMSE =  0.9196423098694533 ± 0.0\n",
      "95th RMSE =  5.077877083218228 ± 0.0\n",
      "MSLL=  1.0922637325560496 ± 0.0\n",
      "Mean RMSE =  1.9670327346686514 ± 0.0\n",
      "Mean R2 =  0.3769794489376289 ± 0.0\n",
      "5th RMSE =  1.0649328671758052 ± 0.0\n",
      "95th RMSE =  4.168218379910711 ± 0.0\n",
      "MSLL=  27390097.713403944 ± 0.0\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "R2_arr = np.array(R2_all)\n",
    "plt.errorbar([0, 2, 4, 8, 15, 30], R2_arr[:, 0], yerr=R2_arr[:, 1],\n",
    "             capsize=5, marker='.', linestyle='none')\n",
    "reg = LinearRegression().fit(\n",
    "    np.array([0, 2, 4, 8, 15, 30]).reshape(-1, 1), R2_arr[:, 0])\n",
    "y = reg.predict(np.linspace(0, 30, 10).reshape(-1, 1))\n",
    "plt.plot(np.linspace(0, 30, 10).reshape(-1, 1), y, linestyle='--')\n",
    "plt.ylabel('$R^2$')\n",
    "plt.xlabel('Years')\n",
    "plt.savefig('appendix_C_plot.png', dpi=300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5426c688bd3257604544373d620790b2306efd3cd4ed9fb4532f758698a84368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
